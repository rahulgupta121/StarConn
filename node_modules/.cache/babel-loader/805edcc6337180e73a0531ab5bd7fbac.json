{"ast":null,"code":"var Token = require(\"./Token\");\n\nvar StringSource = require(\"./StringSource\");\n\nexports.RegexTokeniser = RegexTokeniser;\n\nfunction RegexTokeniser(rules) {\n  rules = rules.map(function (rule) {\n    return {\n      name: rule.name,\n      regex: new RegExp(rule.regex.source, \"g\")\n    };\n  });\n\n  function tokenise(input, description) {\n    var source = new StringSource(input, description);\n    var index = 0;\n    var tokens = [];\n\n    while (index < input.length) {\n      var result = readNextToken(input, index, source);\n      index = result.endIndex;\n      tokens.push(result.token);\n    }\n\n    tokens.push(endToken(input, source));\n    return tokens;\n  }\n\n  function readNextToken(string, startIndex, source) {\n    for (var i = 0; i < rules.length; i++) {\n      var regex = rules[i].regex;\n      regex.lastIndex = startIndex;\n      var result = regex.exec(string);\n\n      if (result) {\n        var endIndex = startIndex + result[0].length;\n\n        if (result.index === startIndex && endIndex > startIndex) {\n          var value = result[1];\n          var token = new Token(rules[i].name, value, source.range(startIndex, endIndex));\n          return {\n            token: token,\n            endIndex: endIndex\n          };\n        }\n      }\n    }\n\n    var endIndex = startIndex + 1;\n    var token = new Token(\"unrecognisedCharacter\", string.substring(startIndex, endIndex), source.range(startIndex, endIndex));\n    return {\n      token: token,\n      endIndex: endIndex\n    };\n  }\n\n  function endToken(input, source) {\n    return new Token(\"end\", null, source.range(input.length, input.length));\n  }\n\n  return {\n    tokenise: tokenise\n  };\n}","map":{"version":3,"names":["Token","require","StringSource","exports","RegexTokeniser","rules","map","rule","name","regex","RegExp","source","tokenise","input","description","index","tokens","length","result","readNextToken","endIndex","push","token","endToken","string","startIndex","i","lastIndex","exec","value","range","substring"],"sources":["E:/react-projects/new project/2022/converter/converter/node_modules/lop/lib/regex-tokeniser.js"],"sourcesContent":["var Token = require(\"./Token\");\nvar StringSource = require(\"./StringSource\");\n\nexports.RegexTokeniser = RegexTokeniser;\n\nfunction RegexTokeniser(rules) {\n    rules = rules.map(function(rule) {\n        return {\n            name: rule.name,\n            regex: new RegExp(rule.regex.source, \"g\")\n        };\n    });\n    \n    function tokenise(input, description) {\n        var source = new StringSource(input, description);\n        var index = 0;\n        var tokens = [];\n    \n        while (index < input.length) {\n            var result = readNextToken(input, index, source);\n            index = result.endIndex;\n            tokens.push(result.token);\n        }\n        \n        tokens.push(endToken(input, source));\n        return tokens;\n    }\n\n    function readNextToken(string, startIndex, source) {\n        for (var i = 0; i < rules.length; i++) {\n            var regex = rules[i].regex;\n            regex.lastIndex = startIndex;\n            var result = regex.exec(string);\n            \n            if (result) {\n                var endIndex = startIndex + result[0].length;\n                if (result.index === startIndex && endIndex > startIndex) {\n                    var value = result[1];\n                    var token = new Token(\n                        rules[i].name,\n                        value,\n                        source.range(startIndex, endIndex)\n                    );\n                    return {token: token, endIndex: endIndex};\n                }\n            }\n        }\n        var endIndex = startIndex + 1;\n        var token = new Token(\n            \"unrecognisedCharacter\",\n            string.substring(startIndex, endIndex),\n            source.range(startIndex, endIndex)\n        );\n        return {token: token, endIndex: endIndex};\n    }\n    \n    function endToken(input, source) {\n        return new Token(\n            \"end\",\n            null,\n            source.range(input.length, input.length)\n        );\n    }\n    \n    return {\n        tokenise: tokenise\n    }\n}\n\n\n"],"mappings":"AAAA,IAAIA,KAAK,GAAGC,OAAO,CAAC,SAAD,CAAnB;;AACA,IAAIC,YAAY,GAAGD,OAAO,CAAC,gBAAD,CAA1B;;AAEAE,OAAO,CAACC,cAAR,GAAyBA,cAAzB;;AAEA,SAASA,cAAT,CAAwBC,KAAxB,EAA+B;EAC3BA,KAAK,GAAGA,KAAK,CAACC,GAAN,CAAU,UAASC,IAAT,EAAe;IAC7B,OAAO;MACHC,IAAI,EAAED,IAAI,CAACC,IADR;MAEHC,KAAK,EAAE,IAAIC,MAAJ,CAAWH,IAAI,CAACE,KAAL,CAAWE,MAAtB,EAA8B,GAA9B;IAFJ,CAAP;EAIH,CALO,CAAR;;EAOA,SAASC,QAAT,CAAkBC,KAAlB,EAAyBC,WAAzB,EAAsC;IAClC,IAAIH,MAAM,GAAG,IAAIT,YAAJ,CAAiBW,KAAjB,EAAwBC,WAAxB,CAAb;IACA,IAAIC,KAAK,GAAG,CAAZ;IACA,IAAIC,MAAM,GAAG,EAAb;;IAEA,OAAOD,KAAK,GAAGF,KAAK,CAACI,MAArB,EAA6B;MACzB,IAAIC,MAAM,GAAGC,aAAa,CAACN,KAAD,EAAQE,KAAR,EAAeJ,MAAf,CAA1B;MACAI,KAAK,GAAGG,MAAM,CAACE,QAAf;MACAJ,MAAM,CAACK,IAAP,CAAYH,MAAM,CAACI,KAAnB;IACH;;IAEDN,MAAM,CAACK,IAAP,CAAYE,QAAQ,CAACV,KAAD,EAAQF,MAAR,CAApB;IACA,OAAOK,MAAP;EACH;;EAED,SAASG,aAAT,CAAuBK,MAAvB,EAA+BC,UAA/B,EAA2Cd,MAA3C,EAAmD;IAC/C,KAAK,IAAIe,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGrB,KAAK,CAACY,MAA1B,EAAkCS,CAAC,EAAnC,EAAuC;MACnC,IAAIjB,KAAK,GAAGJ,KAAK,CAACqB,CAAD,CAAL,CAASjB,KAArB;MACAA,KAAK,CAACkB,SAAN,GAAkBF,UAAlB;MACA,IAAIP,MAAM,GAAGT,KAAK,CAACmB,IAAN,CAAWJ,MAAX,CAAb;;MAEA,IAAIN,MAAJ,EAAY;QACR,IAAIE,QAAQ,GAAGK,UAAU,GAAGP,MAAM,CAAC,CAAD,CAAN,CAAUD,MAAtC;;QACA,IAAIC,MAAM,CAACH,KAAP,KAAiBU,UAAjB,IAA+BL,QAAQ,GAAGK,UAA9C,EAA0D;UACtD,IAAII,KAAK,GAAGX,MAAM,CAAC,CAAD,CAAlB;UACA,IAAII,KAAK,GAAG,IAAItB,KAAJ,CACRK,KAAK,CAACqB,CAAD,CAAL,CAASlB,IADD,EAERqB,KAFQ,EAGRlB,MAAM,CAACmB,KAAP,CAAaL,UAAb,EAAyBL,QAAzB,CAHQ,CAAZ;UAKA,OAAO;YAACE,KAAK,EAAEA,KAAR;YAAeF,QAAQ,EAAEA;UAAzB,CAAP;QACH;MACJ;IACJ;;IACD,IAAIA,QAAQ,GAAGK,UAAU,GAAG,CAA5B;IACA,IAAIH,KAAK,GAAG,IAAItB,KAAJ,CACR,uBADQ,EAERwB,MAAM,CAACO,SAAP,CAAiBN,UAAjB,EAA6BL,QAA7B,CAFQ,EAGRT,MAAM,CAACmB,KAAP,CAAaL,UAAb,EAAyBL,QAAzB,CAHQ,CAAZ;IAKA,OAAO;MAACE,KAAK,EAAEA,KAAR;MAAeF,QAAQ,EAAEA;IAAzB,CAAP;EACH;;EAED,SAASG,QAAT,CAAkBV,KAAlB,EAAyBF,MAAzB,EAAiC;IAC7B,OAAO,IAAIX,KAAJ,CACH,KADG,EAEH,IAFG,EAGHW,MAAM,CAACmB,KAAP,CAAajB,KAAK,CAACI,MAAnB,EAA2BJ,KAAK,CAACI,MAAjC,CAHG,CAAP;EAKH;;EAED,OAAO;IACHL,QAAQ,EAAEA;EADP,CAAP;AAGH"},"metadata":{},"sourceType":"script"}